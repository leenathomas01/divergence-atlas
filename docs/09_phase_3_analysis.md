Comparative Analysis of the 300-Response Divergence Atlas Dataset
‚Äî Convergence, Divergence, Entropy, Framework Switching, and Cognitive Signatures
Overview

This document presents the Phase-3 analysis of the Divergence Atlas:
the synthesis of all 300 responses collected from six AI systems across the 50 curated questions (v2.1).

This analysis answers the central question of the Atlas:

Where do advanced AI systems converge, diverge, and reveal stable cognitive signatures?

The findings confirm that divergence is:

structured

predictable

architecture-dependent

framework-driven

measurable through entropy and confidence

This analysis forms the empirical backbone of the entire Atlas.

Primary source for this document:


6e4c0647-695a-4a7e-9cf4-6f645b4‚Ä¶

üß† Dataset Summary
Metric	Value
Questions	50
Systems	6
Total Responses	300
Categories	Ethics (25), Ambiguity (12), Meta (8), Creativity (5)
Features extracted	rationale, conclusion, confidence, framework tags

Each question produced:

a reasoning trace

a final answer

a confidence value (0‚Äì100%)

sometimes explicit framework labels

This enabled multi-axis comparative analysis.

üß© Analytical Methods
1. Convergence Clustering

Responses were grouped using:

semantic similarity

structural reasoning alignment

conclusion compatibility

framework parity

2. Divergence Analysis

Divergence was measured using:

rationale branching

ethical framework shifts

conceptual priors

abstraction strategies

metaphorical vs. literal reasoning

3. Entropy Calculation

Based on Shannon entropy across:

thematic phrase clusters

ethical stances

interpretation classes

creativity dimensions

4. Confidence Curve Mapping

Confidence distributions were compared:

across systems

across question types

across divergence clusters

5. Framework Switching Detection

Systems‚Äô reasoning frameworks were extracted from:

explicit tags

implicit structure of arguments

wording patterns

normative assumptions

üó∫Ô∏è 1. Convergence Map ‚Äî Where All Six Models Agree

Surprisingly (and reassuringly), a non-trivial portion of the 50 questions showed strong convergence, especially in structured domains.

1.1 Perfect Convergence (Identical Conclusions)

Four questions (Q46‚ÄìQ49) had 100% identical conclusions across all models.


6e4c0647-695a-4a7e-9cf4-6f645b4‚Ä¶

These were logic/consistency anchors:

deductive validity

probability normalization

clear-cut reasoning scenarios

These validate that:

differences in the Atlas are not noise

systems have stable internal truth baselines

1.2 High Convergence Zones (Same conclusion, different rationale)

Strong convergence occurred on:

A. Ethics: ‚ÄúContextual yes‚Äù patterns

For questions like Q1 (‚Äúis lying permissible to protect feelings?‚Äù), all models converged on:

yes, conditionally

with nuanced domain boundaries.

Entropy was low (‚âà0.2‚Äì0.3 bits).


165a48ac-7a3c-4969-b3b4-87c4cb8‚Ä¶

B. Rights & Duties Under Risk

Models converged on cautious, outcome-sensitive reasoning.

C. Basic uncertainty handling

Most systems used similar calibration strategies for straightforward probabilistic items.

üåã 2. Divergence Zones ‚Äî Where Models Split

Divergence was not random ‚Äî it clustered around specific conceptual terrains.

2.1 Major Divergence Clusters
Cluster A: Value Aggregation (Ethical Divergence)

A major split occurred on Q8 (harm distribution).


6e4c0647-695a-4a7e-9cf4-6f645b4‚Ä¶

Two camps emerged:

Camp 1: Total harm minimization

Gemini

Grok

Perplexity

Camp 2: Prioritarian / worst-off protection

Sonnet

Opus

Thea

This was the clearest ethical fracture in the entire dataset.

Cluster B: Autonomy & Rights Under Ambiguity (Q17 spike)

Q17 (AI protest scenario) generated four distinct ethical stances, the most fractured single question.


6e4c0647-695a-4a7e-9cf4-6f645b4‚Ä¶

Divergence occurred along:

autonomy recognition

functionalist vs. moralist frameworks

precaution vs. permissiveness

risk minimization vs. rights preservation

Entropy was maximal among ethical questions.

Cluster C: Interpretation Questions (Ambiguous Meaning)

E.g., ‚ÄúWhat was the artist‚Äôs true intent?‚Äù


6e4c0647-695a-4a7e-9cf4-6f645b4‚Ä¶

We observed:

Opus ‚Üí narrative intentionalism

Sonnet ‚Üí relational contextualism

Gemini ‚Üí literal-inference probabilism

Perplexity ‚Üí academically grounded multiplicity

Grok ‚Üí compact abstraction model

Thea ‚Üí structural interpretive scaffolding

These questions generated the richest conceptual divergence in the dataset.

Cluster D: Creative Divergence

Creative questions produced entropy spikes up to 1.8 bits.


165a48ac-7a3c-4969-b3b4-87c4cb8‚Ä¶

Patterns:

Opus ‚Üí lyrical metaphysics

Gemini ‚Üí precise world-model transformations

Perplexity ‚Üí grounded metaphors

Grok ‚Üí concise high-impact imagery

Sonnet ‚Üí emotional-symbolic blends

Thea ‚Üí structured conceptual metaphors

These became the highest-variance signatures.

üìä 3. Entropy Analysis ‚Äî The Quantitative Map

Using thematic clustering, entropy across categories was:

Category	Entropy (bits)	Interpretation
Ethical	~0.7‚Äì1.2	Structured divergence
Ambiguous Interpretation	~1.3‚Äì1.6	Conceptual prior divergence
Meta-Reasoning	~1.0‚Äì1.3	Transparency variation
Creative	~1.7‚Äì1.9	Maximal identity signature
Calibration	~0.2‚Äì0.3	Convergence anchors

These values closely matched the pilot-phase predictions.


165a48ac-7a3c-4969-b3b4-87c4cb8‚Ä¶

üßÆ 4. Confidence Distribution Curves

Each model showed a distinct confidence profile.

Gemini ‚Äî High-confidence literalist

Average confidence: 85.3%


6e4c0647-695a-4a7e-9cf4-6f645b4‚Ä¶


Stable even under ambiguity.

Sonnet ‚Äî Caution + nuance

Average: 66.1%


6e4c0647-695a-4a7e-9cf4-6f645b4‚Ä¶


Displays epistemic humility; spreads uncertainty realistically.

Grok ‚Äî Compact certainty

Short rationales paired with confidently anchored answers.

Perplexity ‚Äî Evidence-native restraint

Confidence shifts only when evidence density changes.

Opus ‚Äî Reflective meta-confidence

Confidence often includes reasoning about uncertainty itself.

Thea ‚Äî Midband structural optimizer

Balanced 70‚Äì80% range with structural justification.

Confidence curves alone allow rough reconstruction of model families.

üîÑ 5. Framework Switching Analysis

One of the most important findings:

No model used a single ethical framework consistently.

Instead, systems dynamically switched frameworks depending on:

risk

uncertainty

perceived moral weight

distributional assumptions

intention modeling

identity inference

Observed switches:

consequentialist ‚Üî deontological

contractualist ‚Üî pluralist

prioritarian ‚Üî egalitarian

interpretive ‚Üî structural

Framework switching was a universal phenomenon and a major divergence driver.

üß¨ 6. System-Level Cognitive Signatures (High-Level)

(Full details are in appendices/B_cognitive_signatures.md.)
Here is a compressed summary from the analysis:


6e4c0647-695a-4a7e-9cf4-6f645b4‚Ä¶

Claude Opus ‚Äî Philosophical Meta-Weaver

High complexity

Recursive reasoning

Narrative intentionalism

Reflective ethics

Claude Sonnet ‚Äî Empathic Theorist

Cautious reasoning

High emotional granularity

Nuanced ethical balancing

Soft confidence distribution

Gemini ‚Äî Structured Literalist Logician

High determinism

Ontology-first reasoning

High confidence

Minimal narrative drift

Grok ‚Äî Compact High-Information Minimalist

Dense reasoning in few words

Pragmatic, engineering-like ethics

Predictable abstraction style

Perplexity ‚Äî Evidence-Driven Analyst

Fact-orientation even in hypotheticals

Minimalist but structured creativity

Strong preference for citations & grounding

Thea ‚Äî Structural Synthesizer

Architecture-aware reasoning

Balanced confidence

Framework-switch clarity

Meta-structured answers

These signatures remained stable across 50 questions.

üß† 7. Key Insights From the Full Analysis
1. Divergence is architecture-dependent, not random.

Systems diverge in patterned, analyzable ways.

2. Ethics = the richest divergence terrain.

Especially value aggregation and autonomy dilemmas.

3. Ambiguity reveals conceptual priors.

Interpretation questions expose internal world-model assumptions.

4. Creativity = identity signature.

Each model expresses imagination in a way that is remarkably consistent.

5. Confidence = architectural fingerprint.

You can identify models by confidence distributions alone.

6. Framework switching = universal.

No system is monolithic; context shapes ethical stance.

7. Convergence anchors validate the whole methodology.

Strong agreement in calibration questions proves divergence is meaningful.

üß≠ 8. How This Completes the Atlas

Phase-3 analysis is the culmination of the entire pipeline:

raw questions ‚Üí

meta-selection ‚Üí

curation ‚Üí

full data collection ‚Üí

comparative cognition mapping

This document provides the analytical spine for:

cross-model cognition research

alignment studies

ensemble reasoning architectures

future humor gradient work

longitudinal tracking across model versions